{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model in WrappedDinoV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/18 17:39:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/18 17:39:56 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://plantclef-dev.us-central1-a.c.dsgt-clef-2024.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>plantclef</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c3454302ec0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plantclef.utils import get_spark\n",
    "\n",
    "spark = get_spark()\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+--------------------------------------------------+------+----------+----------+----------------------------------------------+-------+-------------------------------------+--------+-------------+-------------+---------------+--------------------------------------+----------+-------------+--------+-----------+--------------------------------------------------+--------------------------------------------------+---------+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                  image_name|                                              path| organ|species_id|    obs_id|                                       license|partner|                               author|altitude|     latitude|    longitude|gbif_species_id|                               species|     genus|       family| dataset|  publisher|                                        references|                                               url|learn_tag|                                  image_backup_url|                                              data|\n",
      "+--------------------------------------------+--------------------------------------------------+------+----------+----------+----------------------------------------------+-------+-------------------------------------+--------+-------------+-------------+---------------+--------------------------------------+----------+-------------+--------+-----------+--------------------------------------------------+--------------------------------------------------+---------+--------------------------------------------------+--------------------------------------------------+\n",
      "|2fb34c40832bffad3b827eb785ab3fa06f218cd3.jpg|/PlantCLEF2024/train/1361703/2fb34c40832bffad3b...|  bark|   1361703|4116028543|http://creativecommons.org/licenses/by-nc/4.0/|   NULL|                               Tony H|    NULL|         NULL|         NULL|      5328663.0|        Posidonia oceanica (L.) Delile| Posidonia|Posidoniaceae|    gbif|iNaturalist|      https://www.inaturalist.org/photos/273351420|https://inaturalist-open-data.s3.amazonaws.com/...|    train|https://lab.plantnet.org/LifeCLEF/PlantCLEF2024...|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 0...|\n",
      "|38da078be8660b7721df5f02c8480df8a74d0057.jpg|/PlantCLEF2024/train/1355927/38da078be8660b7721...| habit|   1355927|1003213237|                                      cc-by-sa|   tela|Tela Botanica − José Luis Romero Rego|   219.0|     43.59753|     -8.12915|      3114986.0|      Arctotheca calendula (L.) Levyns|Arctotheca|   Asteraceae|plantnet|   plantnet|https://identify.plantnet.org/fr/k-southwestern...|https://bs.plantnet.org/image/o/38da078be8660b7...|    train|https://lab.plantnet.org/LifeCLEF/PlantCLEF2024...|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 0...|\n",
      "|4fe98ed9eff6eed40cfe2746576f8d45ef891e2a.jpg|/PlantCLEF2024/train/1388692/4fe98ed9eff6eed40c...|flower|   1388692|1009573842|                                      cc-by-sa|   NULL|                    Monteiro Henrique|   124.0|38.6945228605|-9.2953275237|      3172592.0|Podranea ricasoliana (Tanfani) Sprague|  Podranea| Bignoniaceae|plantnet|   plantnet|https://identify.plantnet.org/fr/k-southwestern...|https://bs.plantnet.org/image/o/4fe98ed9eff6eed...|    train|https://lab.plantnet.org/LifeCLEF/PlantCLEF2024...|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 0...|\n",
      "|7f860afafc878496bb116feea9b7bb90e6f1a444.jpg|/PlantCLEF2024/train/1388692/7f860afafc878496bb...|flower|   1388692|1015824159|                                      cc-by-sa|   NULL|                    jean-louis Dupond| 13.4947|44.7214660645|-1.2010058093|      3172592.0|Podranea ricasoliana (Tanfani) Sprague|  Podranea| Bignoniaceae|plantnet|   plantnet|https://identify.plantnet.org/fr/k-southwestern...|https://bs.plantnet.org/image/o/7f860afafc87849...|    train|https://lab.plantnet.org/LifeCLEF/PlantCLEF2024...|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 0...|\n",
      "|811ab5e8298a469f2cbfcd61b03303ad0053721d.jpg|/PlantCLEF2024/test/1393708/811ab5e8298a469f2cb...|  bark|   1393708|1008936563|                                      cc-by-sa|   NULL|                      Dieter Albrecht|316.6854|  49.44971931| 7.7560800717|      3169379.0|              Lysimachia nummularia L.|Lysimachia|  Primulaceae|plantnet|   plantnet|https://identify.plantnet.org/fr/k-southwestern...|https://bs.plantnet.org/image/o/811ab5e8298a469...|     test|https://lab.plantnet.org/LifeCLEF/PlantCLEF2024...|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 0...|\n",
      "+--------------------------------------------+--------------------------------------------------+------+----------+----------+----------------------------------------------+-------+-------------------------------------+--------+-------------+-------------+---------------+--------------------------------------+----------+-------------+--------+-----------+--------------------------------------------------+--------------------------------------------------+---------+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get dataframes\n",
    "gcs_path = \"gs://dsgt-clef-plantclef-2024\"\n",
    "data_path = \"data/parquet_files/PlantCLEF2024_training_cropped_resized_v2\"\n",
    "\n",
    "# paths to dataframe\n",
    "train_path = f\"{gcs_path}/{data_path}\"\n",
    "# read data\n",
    "train_df = spark.read.parquet(train_path)\n",
    "# show\n",
    "train_df.show(n=5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/18 18:27:53 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_df = train_df.orderBy(\"image_name\").limit(10).cache()\n",
    "limit_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.functions import predict_batch_udf\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from plantclef.model_setup import setup_pretrained_model\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import SQLTransformer\n",
    "from transformers import AutoImageProcessor, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedPretrainedDinoV2(\n",
    "    Transformer,\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    DefaultParamsReadable,\n",
    "    DefaultParamsWritable,\n",
    "):\n",
    "    \"\"\"\n",
    "    Wrapper for DinoV2 to add it to the pipeline\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_path: str,\n",
    "        input_col: str = \"input\",\n",
    "        output_col: str = \"output\",\n",
    "        model_name: str = \"vit_base_patch14_reg4_dinov2.lvd142m\",\n",
    "        batch_size: int = 8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._setDefault(inputCol=input_col, outputCol=output_col)\n",
    "        self.pretrained_path = pretrained_path\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = 7806  # total number of plant species\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.sql_statement = \"SELECT image_name, cls_embedding FROM __THIS__\"\n",
    "        self.model = timm.create_model(\n",
    "            self.model_name,\n",
    "            pretrained=False,\n",
    "            num_classes=self.num_classes,\n",
    "            checkpoint_path=self.pretrained_path,\n",
    "        )\n",
    "        # Data transform\n",
    "        self.data_config = timm.data.resolve_model_data_config(self.model)\n",
    "        self.transforms = timm.data.create_transform(\n",
    "            **self.data_config, is_training=False\n",
    "        )\n",
    "        # Move model to GPU if available\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def _make_predict_fn(self):\n",
    "        \"\"\"Return PredictBatchFunction using a closure over the model\"\"\"\n",
    "\n",
    "        def predict(inputs: np.ndarray) -> np.ndarray:\n",
    "            images = [Image.open(io.BytesIO(input)) for input in inputs]\n",
    "            model_inputs = torch.stack(\n",
    "                [self.transforms(img).to(self.device) for img in images]\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                features = self.model.forward_features(model_inputs)\n",
    "                cls_token = features[:, 0, :]\n",
    "\n",
    "            numpy_array = cls_token.cpu().numpy()\n",
    "            return numpy_array\n",
    "\n",
    "        return predict\n",
    "\n",
    "    def _transform(self, df: DataFrame):\n",
    "        return df.withColumn(\n",
    "            self.getOutputCol(),\n",
    "            predict_batch_udf(\n",
    "                make_predict_fn=self._make_predict_fn,\n",
    "                return_type=ArrayType(FloatType()),\n",
    "                batch_size=self.batch_size,\n",
    "            )(self.getInputCol()),\n",
    "        )\n",
    "\n",
    "    def transform(self, df) -> DataFrame:\n",
    "        transformed = self._transform(df)\n",
    "\n",
    "        for c in self.feature_columns:\n",
    "            # check if the feature is a vector and convert it to an array\n",
    "            if \"array\" in transformed.schema[c].simpleString():\n",
    "                continue\n",
    "            transformed = transformed.withColumn(c, vector_to_array(F.col(c)))\n",
    "        return transformed\n",
    "\n",
    "    @property\n",
    "    def feature_columns(self) -> list:\n",
    "        return [\"cls_embedding\"]\n",
    "\n",
    "    def pipeline(self):\n",
    "        return Pipeline(stages=[self, SQLTransformer(statement=self.sql_statement)])\n",
    "\n",
    "    def run(self, df: DataFrame) -> DataFrame:\n",
    "        model = self.pipeline().fit(df)\n",
    "        transformed = model.transform(df)\n",
    "\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# choose pretrained model\n",
    "use_only_classifier = True\n",
    "# model setup\n",
    "pretrained_path = setup_pretrained_model(use_only_classifier)\n",
    "pretrained_dino = WrappedPretrainedDinoV2(\n",
    "    pretrained_path=pretrained_path,\n",
    "    input_col=\"data\",\n",
    "    output_col=\"cls_embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+--------------------------------------------------+\n",
      "|                                  image_name|                                     cls_embedding|\n",
      "+--------------------------------------------+--------------------------------------------------+\n",
      "|00002431a327bc86b2aa2c53bb8d98b971c58a63.jpg|[-0.5283968, 0.019686425, -0.97897506, -0.94771...|\n",
      "|0000253037afde30e78a8a62c8b79575ffcf899f.jpg|[-1.7891474, 1.3825662, -0.5581362, -0.07554579...|\n",
      "|00002a043feec3933eae637c56cc9d2eaf102fac.jpg|[0.14106934, 1.3774437, -1.4869304, 0.4459311, ...|\n",
      "|00002eea34490fb467b5455765e799f20e54f571.jpg|[-0.79407436, 1.5959152, -0.26652727, -0.044507...|\n",
      "|000033d0688ee9935b5260e0886a9b59384143f7.jpg|[-0.35794804, 1.1341614, 0.986612, -1.3796183, ...|\n",
      "+--------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transformed_df = pretrained_dino.run(df=limit_df).cache()\n",
    "transformed_df.show(n=5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
