{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plantclef.utils import get_spark\n",
    "from pyspark.sql import functions as F\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = get_spark()\n",
    "display(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and dataset names\n",
    "gcs_path = \"gs://dsgt-clef-plantclef-2024/data\"\n",
    "dct_emb_path = \"process/training_cropped_resized_v2/dino_dct/data\"\n",
    "train_path = \"parquet_files/PlantCLEF2024_training_cropped_resized_v2\"\n",
    "\n",
    "# Define the GCS path to the embedding files\n",
    "dct_gcs_path = f\"{gcs_path}/{dct_emb_path}\"\n",
    "train_gcs_path = f\"{gcs_path}/{train_path}\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "dct_df = spark.read.parquet(dct_gcs_path)\n",
    "train_df = spark.read.parquet(train_gcs_path)\n",
    "\n",
    "# Show the data\n",
    "dct_df.show(n=5, truncate=50)\n",
    "train_df.show(n=5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "grouped_df = (\n",
    "    dct_df.groupBy(\"species_id\")\n",
    "    .agg(F.count(\"species_id\").alias(\"n\"))\n",
    "    .orderBy(F.col(\"n\").desc())\n",
    ")\n",
    "\n",
    "# Action\n",
    "grouped_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param\n",
    "num_top_species = 5\n",
    "\n",
    "# Get top species DF\n",
    "top_species = [\n",
    "    int(row[\"species_id\"]) for row in grouped_df.limit(num_top_species).collect()\n",
    "]\n",
    "print(f\"Top {num_top_species} species ids: {top_species}\")\n",
    "\n",
    "subset_df = dct_df.filter(F.col(\"species_id\").isin(top_species)).select(\n",
    "    [\"species_id\", \"dct_embedding\"]\n",
    ")\n",
    "\n",
    "subset_df = subset_df.join(train_df, \"species_id\", \"inner\").select(\n",
    "    [\"species_id\", \"dct_embedding\", \"species\"]\n",
    ")\n",
    "\n",
    "subset_df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = (\n",
    "    subset_df.groupBy(\"species_id\")\n",
    "    .agg(F.count(\"species_id\").alias(\"n\"))\n",
    "    .orderby(\"n\".desc())\n",
    ").show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert to Pandas DF\n",
    "pandas_df = subset_df.select([\"dct_embedding\", \"species\"]).toPandas()\n",
    "\n",
    "# Extract features and labels\n",
    "emb_df = np.stack(pandas_df[\"dct_embedding\"].values)\n",
    "scaled_emb = StandardScaler().fit_transform(emb_df)\n",
    "labels = pandas_df[\"species\"].tolist()\n",
    "\n",
    "# UMAP reduction\n",
    "reducer = umap.UMAP(n_neighbors=15, n_components=2, metric=\"euclidean\", random_state=42)\n",
    "embedding = reducer.fit_transform(scaled_emb)  # NumPy array with shape (n_samples, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(6.4, 4.8), dpi=200)\n",
    "fig.suptitle(\"UMAP projection of top 5 plant species\", fontsize=14, weight=\"bold\")\n",
    "\n",
    "# Create a scatter plot, color-coded by new species_idx\n",
    "colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\"]\n",
    "top_species_idx = pandas_df[\"species\"].value_counts().nlargest(5).index\n",
    "species_to_color = {species: colors[i] for i, species in enumerate(top_species_idx)}\n",
    "\n",
    "# Map species IDs to colors for plotting\n",
    "color_list = pandas_df[\"species\"].map(species_to_color).tolist()\n",
    "\n",
    "for species, color in species_to_color.items():\n",
    "    # Select embeddings for the current species\n",
    "    idx = pandas_df[\"species\"] == species\n",
    "    ax.scatter(\n",
    "        embedding[idx, 0],\n",
    "        embedding[idx, 1],\n",
    "        c=color,\n",
    "        # cmap=\"tab10\",\n",
    "        label=species,\n",
    "        s=5,\n",
    "        alpha=0.7,\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "ax.grid(color=\"blue\", linestyle=\"--\", linewidth=1, alpha=0.2)\n",
    "ax.legend(loc=\"best\", title=\"Species Name\", fontsize=\"small\")\n",
    "for spine in [\"top\", \"right\", \"bottom\", \"left\"]:\n",
    "    ax.spines[spine].set_visible(False)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
